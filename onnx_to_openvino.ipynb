{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "model = ov.convert_model('/home/sr/ov_fr/buffalo_l/det_10g.onnx', example_input=(1, 3, 640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7fb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov.serialize(model, xml_path=\"/home/sr/ov_fr/buffalo_l/det_10g_640.xml\", bin_path=\"/home/sr/ov_fr/buffalo_l/det_10g_640.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5752c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "\n",
    "# 1. Convert your ONNX model to OpenVINO in-memory model (still FP32)\n",
    "model = ov.convert_model(\"/home/sr/ov_fr/buffalo_l/adaface_ir_50_model.onnx\")\n",
    "\n",
    "# 2. Save the IR model to disk, auto-generating both .xml and .bin in FP16\n",
    "ov.save_model(\n",
    "    model,\n",
    "    \"/home/sr/ov_fr/buffalo_l/adaface_ir_50_model_fp16.xml\",\n",
    "    compress_to_fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx \n",
    "model = onnx.load('/home/sr/ov_fr/buffalo_l/adaface_ir_50_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e095081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from nncf import Dataset\n",
    "from typing import List\n",
    "\n",
    "def preprocess_image(image_path: str) -> np.ndarray:\n",
    "    \"\"\"Preprocess a single image for AdaFace (112x112, normalized).\"\"\"\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    \n",
    "    # Resize to 112x112 (AdaFace input size)\n",
    "    img = cv2.resize(img, (112, 112))\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Apply mean and std normalization (adjust as per AdaFace requirements)\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    img = (img - mean) / std\n",
    "    \n",
    "    # Convert to model input format (1, C, H, W)\n",
    "    img = img.transpose(2, 0, 1)  # HWC to CHW\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "def load_images(image_dir: str, max_images: int = 2000) -> List[np.ndarray]:\n",
    "    \"\"\"Load and preprocess images from directory.\"\"\"\n",
    "    image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    if not image_paths:\n",
    "        raise ValueError(f\"No images found in directory: {image_dir}\")\n",
    "    image_paths = image_paths[:max_images]  # Limit to max_images\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            images.append(preprocess_image(path))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping image {path}: {e}\")\n",
    "    return images\n",
    "\n",
    "def create_calibration_dataset(image_dir: str, max_images: int = 2000) -> Dataset:\n",
    "    \"\"\"Create NNCF calibration dataset.\"\"\"\n",
    "    images = load_images(image_dir, max_images)\n",
    "    if not images:\n",
    "        raise ValueError(\"No valid images loaded for calibration dataset\")\n",
    "    def transform_fn(image):\n",
    "        return {\"input\": image}  # Use 'input' to match the model's input name\n",
    "    return Dataset(images, transform_fn)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = \"/home/sr/calib-data\" # Path to your folder with 4000 images\n",
    "    calibration_dataset = create_calibration_dataset(image_dir, max_images=2000)\n",
    "    print(f\"Calibration dataset created with {len(calibration_dataset.get_data())} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cc370b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input names: ['input']\n",
      "Calibration dataset input keys: ['data']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Required inputs (['input']) are missing from input feed (['data']).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalibration dataset input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(sample_data.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Should include 'input'\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Quantize the model to INT-8\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m quantized_model = \u001b[43mnncf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcalibration_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_bias_correction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Improve accuracy\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use 2000 images for calibration\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnncf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTargetDevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCPU\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Optimize for CPU\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Save the quantized ONNX model\u001b[39;00m\n\u001b[32m     32\u001b[39m quantized_model_path = \u001b[33m\"\u001b[39m\u001b[33mquantized_adaface.onnx\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/telemetry/decorator.py:81\u001b[39m, in \u001b[36mtracked_function.__call__.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m     74\u001b[39m         telemetry.send_event(\n\u001b[32m     75\u001b[39m             event_category=category,\n\u001b[32m     76\u001b[39m             event_action=event.name,\n\u001b[32m     77\u001b[39m             event_label=event.data,\n\u001b[32m     78\u001b[39m             event_value=event.int_data,\n\u001b[32m     79\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m retval = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m category \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m category != previous_category:\n\u001b[32m     84\u001b[39m     telemetry.end_session(\u001b[38;5;28mself\u001b[39m._category)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/quantization/quantize_model.py:205\u001b[39m, in \u001b[36mquantize\u001b[39m\u001b[34m(model, calibration_dataset, mode, preset, target_device, subset_size, fast_bias_correction, model_type, ignored_scope, advanced_parameters)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == BackendType.ONNX:\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnncf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantize_impl\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquantize_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[no-any-return]\u001b[39;49;00m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcalibration_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcalibration_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfast_bias_correction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfast_bias_correction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignored_scope\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignored_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43madvanced_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43madvanced_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == BackendType.TENSORFLOW:\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnncf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantize_impl\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/onnx/quantization/quantize_model.py:173\u001b[39m, in \u001b[36mquantize_impl\u001b[39m\u001b[34m(model, calibration_dataset, mode, preset, target_device, subset_size, fast_bias_correction, model_type, ignored_scope, advanced_parameters)\u001b[39m\n\u001b[32m    171\u001b[39m graph = GraphConverter.create_nncf_graph(model)\n\u001b[32m    172\u001b[39m warning_model_no_batchwise_support(graph, advanced_parameters, model_type, OPERATIONS_OUTPUT_HAS_NO_BATCH_AXIS)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m quantized_model = \u001b[43mquantization_algorithm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcalibration_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m external_data_dir:\n\u001b[32m    176\u001b[39m     remove_metadata(model, MetadataKey.EXTERNAL_DATA_DIR)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/quantization/algorithms/post_training/algorithm.py:113\u001b[39m, in \u001b[36mPostTrainingQuantization.apply\u001b[39m\u001b[34m(self, model, graph, statistic_points, dataset)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m statistic_points:\n\u001b[32m    111\u001b[39m     step_index_to_statistics = {\u001b[32m0\u001b[39m: statistic_points}\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_from_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_index_to_statistics\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/quantization/algorithms/pipeline.py:161\u001b[39m, in \u001b[36mPipeline.run_from_step\u001b[39m\u001b[34m(self, model, dataset, graph, start_step_index, step_index_to_statistics)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step_statistics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    160\u001b[39m     statistic_points = \u001b[38;5;28mself\u001b[39m.get_statistic_points_for_step(step_index, step_model, step_graph)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     step_statistics = \u001b[43mcollect_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatistic_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# Run current pipeline step\u001b[39;00m\n\u001b[32m    164\u001b[39m step_model = \u001b[38;5;28mself\u001b[39m.run_step(step_index, step_statistics, step_model, step_graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/quantization/algorithms/pipeline.py:49\u001b[39m, in \u001b[36mcollect_statistics\u001b[39m\u001b[34m(containers, model, graph, dataset)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m container \u001b[38;5;129;01min\u001b[39;00m containers:\n\u001b[32m     48\u001b[39m     statistics_aggregator.register_statistic_points(container)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43mstatistics_aggregator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m statistics_aggregator.statistic_points\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/onnx/statistics/aggregator.py:40\u001b[39m, in \u001b[36mONNXStatisticsAggregator.collect_statistics\u001b[39m\u001b[34m(self, model, graph)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.node_mapping = get_name_to_node_map(model)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mself\u001b[39m._registered_weights = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/common/tensor_statistics/aggregator.py:86\u001b[39m, in \u001b[36mStatisticsAggregator.collect_statistics\u001b[39m\u001b[34m(self, model, graph)\u001b[39m\n\u001b[32m     80\u001b[39m processed_samples = \u001b[32m0\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m input_data \u001b[38;5;129;01min\u001b[39;00m track(\n\u001b[32m     82\u001b[39m     islice(\u001b[38;5;28mself\u001b[39m.dataset.get_inference_data(), iterations_number),\n\u001b[32m     83\u001b[39m     total=iterations_number,\n\u001b[32m     84\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mStatistics collection\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     85\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     outputs = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     processed_outputs = \u001b[38;5;28mself\u001b[39m._process_outputs(outputs)\n\u001b[32m     88\u001b[39m     \u001b[38;5;28mself\u001b[39m._register_statistics(processed_outputs, merged_statistics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/nncf/onnx/engine.py:52\u001b[39m, in \u001b[36mONNXEngine.infer\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np.ndarray]) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np.ndarray]:\n\u001b[32m     46\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m    Runs model on the provided input via ONNXRuntime InferenceSession.\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03m    Returns the dictionary of model outputs by node names.\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03m    :param input_data: inputs for the model\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    :return output_data: models outputs\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     output_tensors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     model_outputs = \u001b[38;5;28mself\u001b[39m.sess.get_outputs()\n\u001b[32m     55\u001b[39m     outputs_safe = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:269\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, output_names, input_feed, run_options)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_names, input_feed, run_options=\u001b[38;5;28;01mNone\u001b[39;00m) -> Sequence[np.ndarray | SparseTensor | \u001b[38;5;28mlist\u001b[39m | \u001b[38;5;28mdict\u001b[39m]:\n\u001b[32m    256\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03m    Compute the predictions.\u001b[39;00m\n\u001b[32m    258\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m \u001b[33;03m        sess.run([output_name], {input_name: x})\u001b[39;00m\n\u001b[32m    268\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_names:\n\u001b[32m    271\u001b[39m         output_names = [output.name \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._outputs_meta]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fdfr/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:251\u001b[39m, in \u001b[36mSession._validate_input\u001b[39m\u001b[34m(self, feed_input_names)\u001b[39m\n\u001b[32m    249\u001b[39m         missing_input_names.append(\u001b[38;5;28minput\u001b[39m.name)\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_input_names:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    252\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequired inputs (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_input_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) are missing from input feed (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeed_input_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Required inputs (['input']) are missing from input feed (['data'])."
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import nncf\n",
    "import openvino as ov\n",
    "from onnx import helper\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"/home/sr/ov_fr/buffalo_l/adaface_ir_50_model.onnx\"  # Replace with your model path\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "# Verify model input name\n",
    "model_inputs = [input.name for input in onnx_model.graph.input]\n",
    "print(f\"Model input names: {model_inputs}\")  # Should include 'input'\n",
    "\n",
    "# Create calibration dataset\n",
    "image_dir = \"/home/sr/calib-data\"  # Path to your folder with 4000 images\n",
    "calibration_dataset = create_calibration_dataset(image_dir, max_images=2000)\n",
    "\n",
    "# Verify calibration dataset input\n",
    "sample_data = next(iter(calibration_dataset.get_inference_data()))\n",
    "print(f\"Calibration dataset input keys: {list(sample_data.keys())}\")  # Should include 'input'\n",
    "\n",
    "# Quantize the model to INT-8\n",
    "quantized_model = nncf.quantize(\n",
    "    onnx_model,\n",
    "    calibration_dataset,\n",
    "    fast_bias_correction=False,  # Improve accuracy\n",
    "    subset_size=2000,  # Use 2000 images for calibration\n",
    "    target_device=nncf.TargetDevice.CPU  # Optimize for CPU\n",
    ")\n",
    "\n",
    "# Save the quantized ONNX model\n",
    "quantized_model_path = \"quantized_adaface.onnx\"\n",
    "onnx.save(quantized_model, quantized_model_path)\n",
    "\n",
    "# Convert to OpenVINO IR\n",
    "ov_model = ov.convert_model(quantized_model_path)\n",
    "\n",
    "# Save the OpenVINO IR model\n",
    "ov.save_model(ov_model, \"adaface_int8.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4671d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
